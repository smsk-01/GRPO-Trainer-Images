# ğŸ–¼ï¸ GRPOÂ ImagesÂ Trainer

Fineâ€‘tune **QwenÂ 2.5â€‘VL** (or any Visionâ€‘Language model with the same API) on image *grounding* tasks using **GRPOÂ (GenericÂ RewardÂ PredictionÂ Optimization)** in just a few lines of code.

<p align="center">
  <img src="https://img.shields.io/badge/python-3.8%2B-blue?logo=python" />
  <img src="https://img.shields.io/badge/License-MIT-green.svg" />
</p>

---

## âœ¨Â Why use this repo?

* **Plugâ€‘andâ€‘play trainer** â€“ drop in your own JSON dataset of promptsÂ +Â boundingâ€‘boxes and start training.  
* **Imageâ€‘aware data collator** â€“ automatically loads, preprocesses and batches images.  
* **Rewardâ€‘based optimisation** â€“ leverages the `trl` libraryâ€™s GRPO algorithm for RLâ€‘style fineâ€‘tuning.  
* **Minimal codebase** â€“ only three Python files, easy to read and customise.  

---

## ğŸ—„Â Repository layout

```text
.
â”œâ”€â”€ GRPOImagesTrainer.py   # custom trainer + model wrapper
â”œâ”€â”€ rewards.py             # reward functions
â””â”€â”€ main.py                # training entryâ€‘point

